{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %pip install pandas -U\n",
    "# # %pip install --upgrade pandas\n",
    "# # %pip install xlrd -U\n",
    "# import pandas as pd\n",
    "# # %pip install --upgrade xlrd\n",
    "# # %pip install statsmodels -U\n",
    "# # %pip install statsmodels==0.13.0\n",
    "\n",
    "# # Winters\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import statsmodels\n",
    "# from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "# import warnings\n",
    "# from tqdm import tqdm\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# import pandas.util.testing as tm\n",
    "# import random\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "# import numpy as np\n",
    "# from statsmodels.stats.weightstats import DescrStatsW\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "years = ['2018','2019','2020','2021']\n",
    "demands = [pd.read_excel(open('demands.xls', 'rb'), sheet_name=year) for year in years]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one dataframe with all the data and add a 'YEAR' column\n",
    "for i in range(len(years)):\n",
    "     demands[i][\"YEAR\"]=int(years[i])\n",
    "total_demands = pd.concat(demands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### DO NOT DELETE #####################\n",
    "# active_sku_ids = total_demands[total_demands['YEAR'] == 2021]['SKU_ID'].unique()\n",
    "# total_demands = total_demands[total_demands['SKU_ID'].isin(active_sku_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load assuta items and remove them from the dataframe\n",
    "assuta_items = pd.read_excel(\"Assuta_items.xlsx\")\n",
    "total_demands = total_demands[~total_demands[\"SKU_ID\"].isin(assuta_items[\"SKU_ID\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group A - find the ~20% with highest demands\n",
    "# for every product, calculate the average demand for the 4 years\n",
    "import matplotlib.pyplot as plt\n",
    "data_b = total_demands.copy()\n",
    "annual_avg = ((data_b.groupby(\"SKU_ID\")[\"TOTAL_FOR_YEAR\"].mean())).to_frame()\n",
    "annual_avg.columns = ['YEARLY_AVG']\n",
    "annual_avg.reset_index(inplace=True)\n",
    "# annual_avg.head()\n",
    "data_c = total_demands.copy()\n",
    "data_merged = pd.merge(data_c, annual_avg, how='inner', on = 'SKU_ID')\n",
    "good_sku_ids = data_merged[[\"SKU_ID\", \"YEARLY_AVG\"]].drop_duplicates().sort_values(by=['YEARLY_AVG'], ascending=False)\n",
    "# a.reset_index(inplace=True)\n",
    "# a.to_csv(r'good_sku_ids.csv', index = False)\n",
    "good_sku_ids['CUMSUM'] = good_sku_ids['YEARLY_AVG'].cumsum()\n",
    "good_sku_ids['CUMSUM_PERC'] = 100*good_sku_ids['CUMSUM']/good_sku_ids['YEARLY_AVG'].sum()\n",
    "plt.plot(np.arange(len(good_sku_ids['CUMSUM_PERC'])),good_sku_ids['CUMSUM_PERC'])\n",
    "good_sku_ids['Up_To'] = good_sku_ids['CUMSUM_PERC'] <= 70\n",
    "good_sku_ids = good_sku_ids[good_sku_ids['Up_To']]\n",
    "a_list_sku_ids = good_sku_ids['SKU_ID']\n",
    "a_list_sku_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_demands = total_demands[total_demands[\"SKU_ID\"].isin(list(a_list_sku_ids))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Nulls with 0.1\n",
    "total_demands.fillna(0.1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_demands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add quarters columns\n",
    "total_demands[\"P1\"] = total_demands[\"'01'\"] + total_demands[\"'02'\"]\n",
    "total_demands[\"P2\"] = total_demands[\"'03'\"] + total_demands[\"'04'\"]\n",
    "total_demands[\"P3\"] = total_demands[\"'05'\"] + total_demands[\"'06'\"]\n",
    "total_demands[\"P4\"] = total_demands[\"'07'\"] + total_demands[\"'08'\"]\n",
    "total_demands[\"P5\"] = total_demands[\"'09'\"] + total_demands[\"'10'\"]\n",
    "total_demands[\"P6\"] = total_demands[\"'11'\"] + total_demands[\"'12'\"]\n",
    "\n",
    "# Add quarters columns\n",
    "total_demands[\"Q1\"] = total_demands[\"'01'\"] + total_demands[\"'02'\"] + total_demands[\"'03'\"]\n",
    "total_demands[\"Q2\"] = total_demands[\"'04'\"] + total_demands[\"'05'\"] + total_demands[\"'06'\"]\n",
    "total_demands[\"Q3\"] = total_demands[\"'07'\"] + total_demands[\"'08'\"] + total_demands[\"'09'\"]\n",
    "total_demands[\"Q4\"] = total_demands[\"'10'\"] + total_demands[\"'11'\"] + total_demands[\"'12'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_demands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_demands['demand_mean'] = np.mean(total_demands.iloc[:,1:13].to_numpy(),axis=1)\n",
    "# total_demands['demand_stdv'] = np.std(total_demands.iloc[:,1:13].to_numpy(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make 3 lists - less (r<9.5), good (9.5<r>10.5), more (r>10.5) while r is the number of refreshes per month\n",
    "refresh = pd.read_csv('refresh.csv')\n",
    "refresh = refresh.iloc[:-1,:] # Remove the last row ('sum' per month)\n",
    "refresh.fillna(0,inplace=True)\n",
    "refresh['mean'] = np.mean(refresh.iloc[:,1:].to_numpy(),axis=1)\n",
    "sku_ids_0to95 = list(refresh[(refresh['mean']>=0)&(refresh['mean']<9.5)]['SKU_ID'])\n",
    "sku_ids_95to105 = list(refresh[(refresh['mean']>=9.5)&(refresh['mean']<=10.5)]['SKU_ID'])\n",
    "sku_ids_over105 = list(refresh[refresh['mean']>10.5]['SKU_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = refresh['mean'].hist(bins=10,grid=False,figsize=[10,5],legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1 = list(total_demands['SKU_ID'])\n",
    "lst2 = sku_ids_0to95 + sku_ids_over105\n",
    "relevant_sku_ids = list(set(lst1) & set(lst2)) # sku_ids of products that is not good (less or more)\n",
    "print(f'The number of relevant sku_ids is: {len(relevant_sku_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stay with only the relevant products\n",
    "total_demands = total_demands[total_demands['SKU_ID'].isin(relevant_sku_ids)]\n",
    "total_demands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = total_demands.copy().iloc[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,18]]\n",
    "data.replace(0.1,0,inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data.SKU_ID=='ULM00180']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add quarters columns\n",
    "data[\"Q1\"] = (data[\"'01'\"] + data[\"'02'\"] + data[\"'03'\"]) / 3\n",
    "data[\"Q2\"] = (data[\"'04'\"] + data[\"'05'\"] + data[\"'06'\"]) / 3\n",
    "data[\"Q3\"] = (data[\"'07'\"] + data[\"'08'\"] + data[\"'09'\"]) / 3\n",
    "data[\"Q4\"] = (data[\"'10'\"] + data[\"'11'\"] + data[\"'12'\"]) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data.SKU_ID=='ULM00180']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Qs = data.iloc[:,data.columns.isin(['SKU_ID','Q1','Q2','Q3','Q4','YEAR'])]\n",
    "data_Qs.reset_index(inplace=True,drop=True)\n",
    "data_Qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_Qs[data_Qs.SKU_ID=='ULM00180']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75bb06568c9d6172a953bbe8382d76fb637459502578ff2e7618bebf03e08899"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
